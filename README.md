# Hi, I'm Wang Zhipeng ðŸ‘‹

<p align="center">
  <img height="220px" width="51%" src="https://github-readme-stats-princeprides-projects.vercel.app/api?username=princepride&show_icons=true&theme=transparent"/>
  <img height="220px" width="39%" src="https://github-readme-stats-princeprides-projects.vercel.app/api/top-langs/?username=princepride&layout=compact&theme=transparent"/>
</p>

I'm a software engineer passionate about building the next generation of AI systems. My work is centered around the **post-training of large models** and developing robust **AI Infrastructure**.

I am a strong believer in the power of open source to democratize AI and address the public's concerns about its rapid advancement. I believe that transparent, collaborative development is the key to building safe and beneficial AI for everyone.

---

### ðŸ”­ My Contributions

I am proud to have contributed to a range of impactful open-source projects across both academia and industry.

#### Academic & Research Projects:
* **[HKUNLP/Dream](https://github.com/HKUNLP/Dream)**: A project focused on [briefly describe the project's goal or your contribution].
* **[thunlp/ProactiveAgent](https://github.com/thunlp/ProactiveAgent)**: An initiative to develop [briefly describe the project's goal or your contribution].
* **[bytedance/tarsier](https://github.com/bytedance/tarsier)**: Contributed to the development of [briefly describe the project's goal or your contribution].

#### Industry-Leading Open Source Projects:
* **[vllm-project/vllm](https://github.com/vllm-project/vllm)**: A high-throughput and memory-efficient inference and serving engine for LLMs.
* **[vllm-project/production-stack](https://github.com/vllm-project/production-stack)**: Focused on building a robust, production-ready stack for serving LLMs with vLLM.
* **[LMCache/LMCache](https://github.com/LMCache/LMCache)**: Redis for LLMs. A project designed to optimize LLM serving by caching KV-pairs.
* **[huggingface/transformers](https://github.com/huggingface/transformers)**: A library of pretrained text, computer vision, audio, video, and multimodal models for inference and training.

---

### ðŸ“« How to reach me:

* [**Email**](wangzhipeng628@gmail.com)
* [**LinkedIn**](https://www.linkedin.com/in/%E5%BF%97%E9%B9%8F-%E6%B1%AA-537882216/)

